Из-за того что в python всё является классом, то даже числа являются экз. класса, как следствие, имеют в себе разные свойства/методы, что занимает много места. Из-за чего Python медленный язык

255 - 11111111 - помещается в байт. современный ПК 8 GB RAM, это 68 719 476 736 бит.
Почему в data analytic важно чтобы данные занимали как можно меньше места? - так как массивы данных очень большие


Например нужно сохранить миллиард записей о возрастах человека
по дефолту числа сохраняются  int64. - нужно 8 GB памяти
Изменив на int8, будет колосальная экономия, это числа от -128 до 127. Вероятно возраст не будет больше 127. При миллиарде нужен 1gb памяти


numpy - библиотека написанная на C, работает быстрее, можем указывать тип данных


в python множества - списки. В других языках - массивы

p = [1, 3, 5, 7] - записаны не сами числа, а хранятся ссылки на эти числа - [#2, #4, #0, #14].
Если список с одинаковым типом данных, то в памяти лучше бы записалось последовательно в каждую ячейку, а не в разброс, но, мы можемм в списке хранить разные типпы данных - какие-то объекты занимают больше одной ячейки, какие-то меньше. Поэтому список хранит просто ссылки на ячейки со значениями

numpy - Если список(уже массив) с одинаковым числовым типом данных(int64, int8), то будет харниться ссылка на 1-й э-т:
a = [1, 3, 5] - а хранит ссылку на 1. А последующие ячейки памяти хранят другие э-ты
также хранится размер для каждой ячейки и размер списка

a = [10^9, 10^11, ...] = a = #0, byte = 8(int64), size=...
|-|-|-|-|-|-|-|-|-|-|-| - 1-й э-т 8 байтов(с 0 до 7), 8-я ячейка памяти - 2-й э-т


NUMPY
на нем основана работа pandas

расчитана на работу с массивами чисел, написан полностью на С - быстрый, оптимизированный. Именно поэтому часто юзать python в DA - есть либа решающая траблы питона, и также можно пользоваться удобным питоном

можно явно указывать размер переменных, экономит память, работает с массивами(array) а не списками, хранит в себе э-ты а не ссылки на них, как  в списке


pandas - решает любые задачи связанные с большим объемом данных